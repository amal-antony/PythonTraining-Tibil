{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350dd282-a800-4822-a18e-107f04cbf2f1",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Data is transferred to RAM using I/O channels so that it can be processed and operation can be performed by Processor.<br>\n",
    "Size of RAM must be greater than size of Data to be processed<br>\n",
    "Else Data wont be processed by RAM<br>\n",
    "If data is 1TB its not practical to increase RAM size to 1TB to process it<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac0240-fe38-4399-86d2-d78c0baf13a3",
   "metadata": {},
   "source": [
    "# Clustered Envirnonment\n",
    "A cluster is a group of multiple server instances, spanning across more than one node, all running identical configurations. <br>\n",
    "All instances in a cluster work together to provide high availability, reliability, and scalability.<br>\n",
    "A server cluster is a unified group of servers, distributed and managed under a single IP address, which serves as a single entity to ensure higher availability, \n",
    "proper load balancing, and system scalability. <br>\n",
    "Each server is a node with its own storage (hard drive), memory (RAM), and processing (CPU) resources to command.<br>\n",
    "A two-node cluster, for instance, means that if one server crashes, the second will immediately take over. <br>\n",
    "Multiple web and app nodes are utilized to guarantee hardware redundancy. This kind of architecture, known as a high-availability cluster, prevents downtime if component failure hits. <br>\n",
    "If the OS fails, which does not have redundancy in a single-standing server. Users will not even know that the server crashed.<br>\n",
    "\n",
    "We can distribute our data to different systems.Eg 100 GB data can be distributed to 4 systems as 10GB , 20 GB, 30GB , 40 GB <br>\n",
    "it takes less time for systems to process 10-40GB than 100 GB as a whole<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a3ee8-b99e-4f10-a127-f8cd5c55ca46",
   "metadata": {},
   "source": [
    "# Big Data - 5 V`s\n",
    "\n",
    "## 1. Volume \n",
    "The size of data<br>\n",
    "Can be structured as well as unstructured\n",
    "## 2. Velocity\n",
    "The speed at which data is generated\n",
    "## 3. Variety\n",
    "The different types of data\n",
    "## 4. Veracity\n",
    "The trustworthiness of data in terms of accuracy\n",
    "## 5. Value\n",
    "Data must be turned into meaningful value or else data in millions is useless\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def4853-7959-4508-a151-83ae85293649",
   "metadata": {},
   "source": [
    "# Hadoop-History\n",
    "\n",
    "## GFS-\n",
    "Google File System <br>\n",
    "File stored in distributed manner<br>\n",
    "Although Google released Map Reduce function hadnt implemented it\n",
    "\n",
    "\n",
    "## Hadoop\n",
    "Released by Yahoo<br>\n",
    "The solution to Big data<br>\n",
    "Hadoop has 3 units\n",
    "### 1.HDFS\n",
    "Hadoop Distributed file system<br>\n",
    "The unit that stores the data<br>\n",
    "A file system and not a database<br>\n",
    "Data is stored as partitions depending on size of the data<br>\n",
    "\n",
    "### 2. MapReduce\n",
    "The unit that does computations<br>\n",
    "2 components map and Reduce\n",
    "#### Map\n",
    "Operation performed on parallel on the small portion of data\n",
    "#### Reduce\n",
    "Combines all results which are extracted from the map\n",
    "\n",
    "\n",
    "### 3. YARN\n",
    "Manages resources- also called as a resource manager<br>\n",
    "\n",
    "Hadoop works on master slave architecture\n",
    "Yarn has 2 components\n",
    "#### Resource Manager\n",
    "Runs resources on Master node<br>\n",
    "Assigns and Keeps track of task assigned to slaves<br>\n",
    "#### Node Manager\n",
    "Runs on slave node<br>\n",
    "Each node saves data on partition and performs task assigned to it<br>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7202a-2ada-4b65-8583-ceaee991632a",
   "metadata": {},
   "source": [
    "# Apache Spark\n",
    "Spark is not an entire replacement for Apache Hadoop <br>\n",
    "It is just a replacement for MapReduce<br>\n",
    "3 units\n",
    "\n",
    "### 1.Storage\n",
    "The unit that stores the data<br>\n",
    "A file system and not a database<br>\n",
    "can be HDFS,Local Data , Amazon s3<br>\n",
    "Data is stored as partitions depending on size of the data<br>\n",
    "\n",
    "### 2. COmpute Engine\n",
    "Spark<br>\n",
    "\n",
    "### 3. Resource Manager\n",
    "Manages resources- also called as a resource manager<br>\n",
    "Can use the following<br>\n",
    "#### Spark-Internal resource Manager\n",
    "#### MESOS\n",
    "#### Kubernetes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cef0c7-c99d-43ae-8e04-b679f92fc8b2",
   "metadata": {},
   "source": [
    "## StandAlone vs Distributed\n",
    "\n",
    "### Distrbuted\n",
    "HDFS and YARN in our Spark cluster \n",
    "### StandAlone\n",
    "Not using HDFS and YARN in our Spark Cluster\n",
    "\n",
    "\n",
    "## Steps Involved\n",
    "1.Define the source of the data<br>\n",
    "2.Ingest-Integrate the data and store it in one place<br>\n",
    "3.Process Operation on the data using MapReduce/Spark<br>\n",
    "4.Store the processed data in some format<br>\n",
    "5.Serve the data<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
